{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Concordances\n",
    "\n",
    "This notebook shows how you can generate a concordance using lists of tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we see what text files we have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullText.txt                performanceConcordance.txt\r\n",
      "Hume Enquiry.txt            theWritingStory.txt\r\n",
      "StoryOfWriting.txt          truthConcordance.txt\r\n",
      "bigdata.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls *.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the \"Hume Enquiry.txt\" from the Gutenberg Project. You can use whatever text you want. We print the first 50 characters to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This string has 366798 characters.\n",
      "The Project Gutenberg EBook of An Enquiry Concerni\n"
     ]
    }
   ],
   "source": [
    "theText2Use = \"Hume Enquiry.txt\"\n",
    "with open(theText2Use, \"r\") as fileToRead:\n",
    "    fileRead = fileToRead.read()\n",
    "    \n",
    "print(\"This string has\", len(fileRead), \"characters.\")\n",
    "print(fileRead[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Text\n",
    "\n",
    "Coming from Gutenberg I need to remove their material from the front and end.\n",
    "\n",
    "First we get the stuff at the front."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "AN ENQUIRY CONCERNING HUMAN UNDERSTAND\n"
     ]
    }
   ],
   "source": [
    "text2find = \"Distributed Proofreaders\"\n",
    "lengthOfT2F = len(text2find)\n",
    "location = fileRead.find(text2find)\n",
    "up2location = location + lengthOfT2F\n",
    "# print(fileRead[location - 20:location + 20 + lengthOfT2F]) # Use to check.\n",
    "theFullText1 = fileRead[up2location:]\n",
    "print(theFullText1[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the stuff at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on, 57.\n",
      "\n",
      "  Freedom of (v. _Necessity_).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text2find = \"End of the Project Gutenberg EBook\"\n",
    "location = theFullText1.find(text2find)\n",
    "# print(fileRead[location:location + 20 + lengthOfT2F]) # Use to check.\n",
    "theFullText = theFullText1[:location]\n",
    "print(theFullText[-50:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "Now we tokenize the text producing a list called \"listOfTokens\" and check the first words. This eliminate punctuation and lowercases the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['an', 'enquiry', 'concerning', 'human', 'understanding', 'by', 'david', 'hume', 'extracted', 'from']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "listOfTokens = re.findall(r'\\b\\w[\\w-]*\\b', theFullText.lower())\n",
    "print(listOfTokens[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function\n",
    "\n",
    "Here is the main function that does the work populating a new list with the lines of concordance. We check the first 5 concordance lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeConc(word2conc,list2FindIn,context2Use,concList):\n",
    "    # Lets get \n",
    "    end = len(list2FindIn)\n",
    "    for location in range(end):\n",
    "        if list2FindIn[location] == word2conc:\n",
    "            # Here we check whether we are at the very beginning or end\n",
    "            if (location - context2Use) < 0:\n",
    "                beginCon = 0\n",
    "            else:\n",
    "                beginCon = location - context2Use\n",
    "                \n",
    "            if (location + context2Use) > end:\n",
    "                endCon = end\n",
    "            else:\n",
    "                endCon = location + context2Use + 1\n",
    "                \n",
    "            theContext = (list2FindIn[beginCon:endCon])\n",
    "            concordanceLine = ' '.join(theContext)\n",
    "            # print(str(location) + \": \" + concordanceLine)\n",
    "            concList.append(str(location) + \": \" + concordanceLine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input and Run\n",
    "\n",
    "Now we have code to run that asks for the word to concord and context. This generates the concordance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What word do you want concordances for? truth\n",
      "How much context do you want? 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ask for the word to search for\n",
    "word2find = input(\"What word do you want concordances for? \").lower() \n",
    "\n",
    "# This asks for the context of words on either side to grab\n",
    "context = input(\"How much context do you want? \") \n",
    "\n",
    "theConc = []\n",
    "makeConc(word2find,listOfTokens,int(context),theConc)\n",
    "theConc[:5]\n",
    "len(theConc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['468: should not yet have fixed beyond controversy the foundation of morals reasoning and criticism and should for ever talk of truth and falsehood vice and virtue beauty and deformity without being able to determine the source of these distinctions while they',\n",
       " '2919: that what is really distinct to the immediate perception may be distinguished by reflexion and consequently that there is a truth and falsehood in all propositions on this subject and a truth and falsehood which lie not beyond the compass of',\n",
       " '2930: distinguished by reflexion and consequently that there is a truth and falsehood in all propositions on this subject and a truth and falsehood which lie not beyond the compass of human understanding there are many obvious distinctions of this kind such',\n",
       " '3686: happy if we can unite the boundaries of the different species of philosophy by reconciling profound enquiry with clearness and truth with novelty and still more happy if reasoning in this easy manner we can undermine the foundations of an abstruse',\n",
       " '6509: are the second objects of human reason are not ascertained in the same manner nor is our evidence of their truth however great of a like nature with the foregoing the contrary of every matter of fact is still possible because']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theConc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "\n",
    "Any concordance we like we can output to a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "nameOfResults = word2find.capitalize() + \".Concordance.txt\"\n",
    "\n",
    "with open(nameOfResults, \"w\") as fileToWrite:\n",
    "    for line in theConc:\n",
    "        fileToWrite.write(line + \"\\n\")\n",
    "    \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we check that the file was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic CSV Handling.ipynb             Truth.Concordance.txt\r\n",
      "Concordances.ipynb                   Truths.Concordance.txt\r\n",
      "ExampleTable.csv                     Untitled.ipynb\r\n",
      "Exploring a text with NLTK.ipynb     Untitled1.ipynb\r\n",
      "Hume Enquiry.txt                     Untitled2.ipynb\r\n",
      "Python language notes.ipynb          theText.txt\r\n",
      "Teaching IPython to Humanists.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "[CC BY-SA](https://creativecommons.org/licenses/by-sa/4.0/) From [The Art of Literary Text Analysis](ArtOfLiteraryTextAnalysis.ipynb) by [St√©fan Sinclair](http://stefansinclair.name) &amp; [Geoffrey Rockwell](http://geoffreyrockwell.com)<br >Created October, 2016 (Jupyter 4.2.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
